17:43:28 1565685808912 training Start
17:43:29 1565685809970 step 0, accuracy 0.2
17:43:30 1565685810436 step 100, accuracy nan
17:43:30 1565685810875 step 200, accuracy nan
17:43:31 1565685811331 step 300, accuracy nan
17:43:31 1565685811802 step 400, accuracy nan
17:43:32 1565685812269 step 500, accuracy nan
17:43:32 1565685812743 step 600, accuracy nan
17:43:33 1565685813203 step 700, accuracy nan
17:43:33 1565685813674 step 800, accuracy nan
17:43:34 1565685814147 step 900, accuracy nan
17:43:34 1565685814622 step 1000, accuracy nan
17:43:35 1565685815068 step 1100, accuracy nan
17:43:35 1565685815514 step 1200, accuracy nan
17:43:35 1565685815958 step 1300, accuracy nan
17:43:36 1565685816422 step 1400, accuracy nan
17:43:36 1565685816883 step 1500, accuracy nan
17:43:37 1565685817344 step 1600, accuracy nan
17:43:37 1565685817764 step 1700, accuracy nan
17:43:38 1565685818188 step 1800, accuracy nan
17:43:38 1565685818649 step 1900, accuracy nan
17:43:39 1565685819083 step 2000, accuracy nan
17:43:39 1565685819523 step 2100, accuracy nan
17:43:39 1565685819992 step 2200, accuracy nan
17:43:40 1565685820468 step 2300, accuracy nan
17:43:40 1565685820947 step 2400, accuracy nan
17:43:41 1565685821423 step 2500, accuracy nan
17:43:41 1565685821894 step 2600, accuracy nan
17:43:42 1565685822358 step 2700, accuracy nan
17:43:42 1565685822826 step 2800, accuracy nan
17:43:43 1565685823303 step 2900, accuracy nan
17:43:43 1565685823782 step 3000, accuracy nan
17:43:44 1565685824269 step 3100, accuracy nan
17:43:44 1565685824759 step 3200, accuracy nan
17:43:45 1565685825232 step 3300, accuracy nan
17:43:45 1565685825657 step 3400, accuracy nan
17:43:46 1565685826076 step 3500, accuracy nan
17:43:46 1565685826528 step 3600, accuracy nan
17:43:46 1565685826972 step 3700, accuracy nan
17:43:47 1565685827435 step 3800, accuracy nan
17:43:47 1565685827895 step 3900, accuracy nan
17:43:48 1565685828345 step 4000, accuracy nan
17:43:48 1565685828820 step 4100, accuracy nan
17:43:49 1565685829297 step 4200, accuracy nan
17:43:49 1565685829761 step 4300, accuracy nan
17:43:50 1565685830225 step 4400, accuracy nan
17:43:50 1565685830670 step 4500, accuracy nan
17:43:51 1565685831128 step 4600, accuracy nan
17:43:51 1565685831593 step 4700, accuracy nan
17:43:52 1565685832057 step 4800, accuracy nan
17:43:52 1565685832529 step 4900, accuracy nan
17:43:52 1565685832997 step 5000, accuracy nan
17:43:53 1565685833459 step 5100, accuracy nan
17:43:53 1565685833923 step 5200, accuracy nan
17:43:54 1565685834378 step 5300, accuracy nan
17:43:54 1565685834823 step 5400, accuracy nan
17:43:55 1565685835267 step 5500, accuracy nan
17:43:55 1565685835736 step 5600, accuracy nan
17:43:56 1565685836206 step 5700, accuracy nan
17:43:56 1565685836687 step 5800, accuracy nan
17:43:57 1565685837162 step 5900, accuracy nan
17:43:57 1565685837628 step 6000, accuracy nan
17:43:58 1565685838092 step 6100, accuracy nan
17:43:58 1565685838563 step 6200, accuracy nan
17:43:59 1565685839011 step 6300, accuracy nan
17:43:59 1565685839475 step 6400, accuracy nan
17:43:59 1565685839942 step 6500, accuracy nan
17:44:00 1565685840396 step 6600, accuracy nan
17:44:00 1565685840856 step 6700, accuracy nan
17:44:01 1565685841346 step 6800, accuracy nan
17:44:01 1565685841807 step 6900, accuracy nan
17:44:02 1565685842268 step 7000, accuracy nan
17:44:02 1565685842749 step 7100, accuracy nan
17:44:03 1565685843227 step 7200, accuracy nan
17:44:03 1565685843709 step 7300, accuracy nan
17:44:04 1565685844174 step 7400, accuracy nan
17:44:04 1565685844655 step 7500, accuracy nan
17:44:05 1565685845135 step 7600, accuracy nan
17:44:05 1565685845620 step 7700, accuracy nan
17:44:06 1565685846090 step 7800, accuracy nan
17:44:06 1565685846569 step 7900, accuracy nan
17:44:07 1565685847037 step 8000, accuracy nan
17:44:07 1565685847513 step 8100, accuracy nan
17:44:07 1565685847987 step 8200, accuracy nan
17:44:08 1565685848479 step 8300, accuracy nan
17:44:08 1565685848964 step 8400, accuracy nan
17:44:09 1565685849445 step 8500, accuracy nan
17:44:09 1565685849914 step 8600, accuracy nan
17:44:10 1565685850391 step 8700, accuracy nan
17:44:10 1565685850855 step 8800, accuracy nan
17:44:11 1565685851324 step 8900, accuracy nan
17:44:11 1565685851795 step 9000, accuracy nan
17:44:12 1565685852262 step 9100, accuracy nan
17:44:12 1565685852751 step 9200, accuracy nan
17:44:13 1565685853247 step 9300, accuracy nan
17:44:13 1565685853719 step 9400, accuracy nan
17:44:14 1565685854204 step 9500, accuracy nan
17:44:14 1565685854677 step 9600, accuracy nan
17:44:15 1565685855145 step 9700, accuracy nan
17:44:15 1565685855632 step 9800, accuracy nan
17:44:16 1565685856117 step 9900, accuracy nan
17:44:16 1565685856584 step 10000, accuracy nan
17:44:17 1565685857068 step 10100, accuracy nan
17:44:17 1565685857534 step 10200, accuracy nan
17:44:18 1565685858001 step 10300, accuracy nan
17:44:18 1565685858467 step 10400, accuracy nan
17:44:18 1565685858942 step 10500, accuracy nan
17:44:19 1565685859417 step 10600, accuracy nan
17:44:19 1565685859894 step 10700, accuracy nan
17:44:20 1565685860378 step 10800, accuracy nan
17:44:20 1565685860848 step 10900, accuracy nan
17:44:21 1565685861333 step 11000, accuracy nan
17:44:21 1565685861805 step 11100, accuracy nan
17:44:22 1565685862280 step 11200, accuracy nan
17:44:22 1565685862742 step 11300, accuracy nan
17:44:23 1565685863192 step 11400, accuracy nan
17:44:23 1565685863653 step 11500, accuracy nan
17:44:24 1565685864134 step 11600, accuracy nan
17:44:24 1565685864617 step 11700, accuracy nan
17:44:25 1565685865100 step 11800, accuracy nan
17:44:25 1565685865556 step 11900, accuracy nan
17:44:26 1565685866007 step 12000, accuracy nan
17:44:26 1565685866467 step 12100, accuracy nan
17:44:26 1565685866920 step 12200, accuracy nan
17:44:27 1565685867374 step 12300, accuracy nan
17:44:27 1565685867854 step 12400, accuracy nan
17:44:28 1565685868345 step 12500, accuracy nan
17:44:28 1565685868826 step 12600, accuracy nan
17:44:29 1565685869303 step 12700, accuracy nan
17:44:29 1565685869769 step 12800, accuracy nan
17:44:30 1565685870236 step 12900, accuracy nan
17:44:30 1565685870700 step 13000, accuracy nan
17:44:31 1565685871179 step 13100, accuracy nan
17:44:31 1565685871646 step 13200, accuracy nan
17:44:32 1565685872134 step 13300, accuracy nan
17:44:32 1565685872622 step 13400, accuracy nan
17:44:33 1565685873095 step 13500, accuracy nan
17:44:33 1565685873566 step 13600, accuracy nan
17:44:34 1565685874031 step 13700, accuracy nan
17:44:34 1565685874495 step 13800, accuracy nan
17:44:34 1565685874968 step 13900, accuracy nan
17:44:35 1565685875443 step 14000, accuracy nan
17:44:35 1565685875927 step 14100, accuracy nan
17:44:36 1565685876405 step 14200, accuracy nan
17:44:36 1565685876883 step 14300, accuracy nan
17:44:37 1565685877361 step 14400, accuracy nan
17:44:37 1565685877843 step 14500, accuracy nan
17:44:38 1565685878328 step 14600, accuracy nan
17:44:38 1565685878799 step 14700, accuracy nan
17:44:39 1565685879275 step 14800, accuracy nan
17:44:39 1565685879753 step 14900, accuracy nan
17:44:40 1565685880215 step 15000, accuracy nan
17:44:40 1565685880215 training Finish
17:44:40 1565685880226 test Start
17:44:40 1565685880274 test finish
17:44:40 1565685880290 2-fold 1th
17:44:40 1565685880290 accuracy : 0.12
17:44:40 1565685880290 precision : 0.024
17:44:40 1565685880291 recall : 0.2
17:44:40 1565685880291 f1 Score : 0.04285714285714285
17:44:40 1565685880291 confution matrix[[0 4 0 0 0]
 [0 3 0 0 0]
 [0 7 0 0 0]
 [0 6 0 0 0]
 [0 5 0 0 0]]
17:44:41 1565685881067 training Start
17:44:41 1565685881130 step 0, accuracy nan
17:44:41 1565685881599 step 100, accuracy nan
17:44:42 1565685882053 step 200, accuracy nan
17:44:42 1565685882511 step 300, accuracy nan
17:44:42 1565685882988 step 400, accuracy nan
17:44:43 1565685883469 step 500, accuracy nan
17:44:43 1565685883927 step 600, accuracy nan
17:44:44 1565685884411 step 700, accuracy nan
17:44:44 1565685884893 step 800, accuracy nan
17:44:45 1565685885358 step 900, accuracy nan
17:44:45 1565685885808 step 1000, accuracy nan
17:44:46 1565685886255 step 1100, accuracy nan
17:44:46 1565685886734 step 1200, accuracy nan
17:44:47 1565685887181 step 1300, accuracy nan
17:44:47 1565685887645 step 1400, accuracy nan
17:44:48 1565685888102 step 1500, accuracy nan
17:44:48 1565685888591 step 1600, accuracy nan
17:44:49 1565685889083 step 1700, accuracy nan
17:44:49 1565685889584 step 1800, accuracy nan
17:44:50 1565685890079 step 1900, accuracy nan
17:44:50 1565685890574 step 2000, accuracy nan
17:44:51 1565685891057 step 2100, accuracy nan
17:44:51 1565685891532 step 2200, accuracy nan
17:44:52 1565685892003 step 2300, accuracy nan
17:44:52 1565685892470 step 2400, accuracy nan
17:44:52 1565685892938 step 2500, accuracy nan
17:44:53 1565685893395 step 2600, accuracy nan
17:44:53 1565685893864 step 2700, accuracy nan
17:44:54 1565685894331 step 2800, accuracy nan
17:44:54 1565685894794 step 2900, accuracy nan
17:44:55 1565685895254 step 3000, accuracy nan
17:44:55 1565685895729 step 3100, accuracy nan
17:44:56 1565685896191 step 3200, accuracy nan
17:44:56 1565685896676 step 3300, accuracy nan
17:44:57 1565685897157 step 3400, accuracy nan
17:44:57 1565685897645 step 3500, accuracy nan
17:44:58 1565685898115 step 3600, accuracy nan
17:44:58 1565685898585 step 3700, accuracy nan
17:44:59 1565685899052 step 3800, accuracy nan
17:44:59 1565685899535 step 3900, accuracy nan
17:45:00 1565685900014 step 4000, accuracy nan
17:45:00 1565685900491 step 4100, accuracy nan
17:45:00 1565685900968 step 4200, accuracy nan
17:45:01 1565685901441 step 4300, accuracy nan
17:45:01 1565685901918 step 4400, accuracy nan
17:45:02 1565685902369 step 4500, accuracy nan
17:45:02 1565685902840 step 4600, accuracy nan
17:45:03 1565685903329 step 4700, accuracy nan
17:45:03 1565685903823 step 4800, accuracy nan
17:45:04 1565685904311 step 4900, accuracy nan
17:45:04 1565685904799 step 5000, accuracy nan
17:45:05 1565685905275 step 5100, accuracy nan
17:45:05 1565685905716 step 5200, accuracy nan
17:45:06 1565685906185 step 5300, accuracy nan
17:45:06 1565685906649 step 5400, accuracy nan
17:45:07 1565685907112 step 5500, accuracy nan
17:45:07 1565685907591 step 5600, accuracy nan
17:45:08 1565685908072 step 5700, accuracy nan
17:45:08 1565685908543 step 5800, accuracy nan
17:45:09 1565685909040 step 5900, accuracy nan
17:45:09 1565685909535 step 6000, accuracy nan
17:45:10 1565685910002 step 6100, accuracy nan
17:45:10 1565685910452 step 6200, accuracy nan
17:45:10 1565685910916 step 6300, accuracy nan
17:45:11 1565685911373 step 6400, accuracy nan
17:45:11 1565685911849 step 6500, accuracy nan
17:45:12 1565685912328 step 6600, accuracy nan
17:45:12 1565685912810 step 6700, accuracy nan
17:45:13 1565685913280 step 6800, accuracy nan
17:45:13 1565685913751 step 6900, accuracy nan
17:45:14 1565685914219 step 7000, accuracy nan
17:45:14 1565685914698 step 7100, accuracy nan
17:45:15 1565685915170 step 7200, accuracy nan
17:45:15 1565685915638 step 7300, accuracy nan
17:45:16 1565685916118 step 7400, accuracy nan
17:45:16 1565685916601 step 7500, accuracy nan
17:45:17 1565685917074 step 7600, accuracy nan
17:45:17 1565685917547 step 7700, accuracy nan
17:45:18 1565685918013 step 7800, accuracy nan
17:45:18 1565685918482 step 7900, accuracy nan
17:45:18 1565685918952 step 8000, accuracy nan
17:45:19 1565685919430 step 8100, accuracy nan
17:45:19 1565685919903 step 8200, accuracy nan
17:45:20 1565685920378 step 8300, accuracy nan
17:45:20 1565685920863 step 8400, accuracy nan
17:45:21 1565685921348 step 8500, accuracy nan
17:45:21 1565685921795 step 8600, accuracy nan
17:45:22 1565685922247 step 8700, accuracy nan
17:45:22 1565685922725 step 8800, accuracy nan
17:45:23 1565685923184 step 8900, accuracy nan
17:45:23 1565685923661 step 9000, accuracy nan
17:45:24 1565685924137 step 9100, accuracy nan
17:45:24 1565685924639 step 9200, accuracy nan
17:45:25 1565685925151 step 9300, accuracy nan
17:45:25 1565685925642 step 9400, accuracy nan
17:45:26 1565685926128 step 9500, accuracy nan
17:45:26 1565685926604 step 9600, accuracy nan
17:45:27 1565685927063 step 9700, accuracy nan
17:45:27 1565685927543 step 9800, accuracy nan
17:45:28 1565685928053 step 9900, accuracy nan
17:45:28 1565685928529 step 10000, accuracy nan
17:45:29 1565685929020 step 10100, accuracy nan
17:45:29 1565685929482 step 10200, accuracy nan
17:45:29 1565685929930 step 10300, accuracy nan
17:45:30 1565685930377 step 10400, accuracy nan
17:45:30 1565685930836 step 10500, accuracy nan
17:45:31 1565685931306 step 10600, accuracy nan
17:45:31 1565685931778 step 10700, accuracy nan
17:45:32 1565685932260 step 10800, accuracy nan
17:45:32 1565685932735 step 10900, accuracy nan
17:45:33 1565685933212 step 11000, accuracy nan
17:45:33 1565685933674 step 11100, accuracy nan
17:45:34 1565685934144 step 11200, accuracy nan
17:45:34 1565685934592 step 11300, accuracy nan
17:45:35 1565685935074 step 11400, accuracy nan
17:45:35 1565685935556 step 11500, accuracy nan
17:45:36 1565685936018 step 11600, accuracy nan
17:45:36 1565685936482 step 11700, accuracy nan
17:45:36 1565685936962 step 11800, accuracy nan
17:45:37 1565685937431 step 11900, accuracy nan
17:45:37 1565685937884 step 12000, accuracy nan
17:45:38 1565685938354 step 12100, accuracy nan
17:45:38 1565685938828 step 12200, accuracy nan
17:45:39 1565685939305 step 12300, accuracy nan
17:45:39 1565685939787 step 12400, accuracy nan
17:45:40 1565685940278 step 12500, accuracy nan
17:45:40 1565685940762 step 12600, accuracy nan
17:45:41 1565685941244 step 12700, accuracy nan
17:45:41 1565685941741 step 12800, accuracy nan
17:45:42 1565685942194 step 12900, accuracy nan
17:45:42 1565685942667 step 13000, accuracy nan
17:45:43 1565685943144 step 13100, accuracy nan
17:45:43 1565685943615 step 13200, accuracy nan
17:45:44 1565685944108 step 13300, accuracy nan
17:45:44 1565685944592 step 13400, accuracy nan
17:45:45 1565685945074 step 13500, accuracy nan
17:45:45 1565685945536 step 13600, accuracy nan
17:45:45 1565685945992 step 13700, accuracy nan
17:45:46 1565685946466 step 13800, accuracy nan
17:45:46 1565685946920 step 13900, accuracy nan
17:45:47 1565685947384 step 14000, accuracy nan
17:45:47 1565685947864 step 14100, accuracy nan
17:45:48 1565685948358 step 14200, accuracy nan
17:45:48 1565685948850 step 14300, accuracy nan
17:45:49 1565685949340 step 14400, accuracy nan
17:45:49 1565685949827 step 14500, accuracy nan
17:45:50 1565685950291 step 14600, accuracy nan
17:45:50 1565685950779 step 14700, accuracy nan
17:45:51 1565685951275 step 14800, accuracy nan
17:45:51 1565685951764 step 14900, accuracy nan
17:45:52 1565685952248 step 15000, accuracy nan
17:45:52 1565685952249 training Finish
17:45:52 1565685952259 test Start
17:45:52 1565685952318 test finish
17:45:52 1565685952322 2-fold 2th
17:45:52 1565685952322 accuracy : 0.24
17:45:52 1565685952322 precision : 0.048
17:45:52 1565685952322 recall : 0.2
17:45:52 1565685952322 f1 Score : 0.07741935483870968
17:45:52 1565685952322 confution matrix[[6 0 0 0 0]
 [7 0 0 0 0]
 [3 0 0 0 0]
 [4 0 0 0 0]
 [5 0 0 0 0]]
17:45:52 1565685952322 total Accuracy : 0.18
17:45:52 1565685952322 total Precision : 0.036000000000000004
17:45:52 1565685952322 total Recall : 0.2
17:45:52 1565685952322 total f1 score : 0.06013824884792626
17:47:45 1565686065307 training Start
17:47:46 1565686066377 step 0, accuracy 0.2
17:47:46 1565686066855 step 100, accuracy nan
17:47:47 1565686067089 training Finish
17:47:47 1565686067094 test Start
17:47:47 1565686067126 test finish
17:47:47 1565686067131 2-fold 1th
17:47:47 1565686067131 accuracy : 0.16
17:47:47 1565686067131 precision : 0.032
17:47:47 1565686067131 recall : 0.2
17:47:47 1565686067131 f1 Score : 0.05517241379310346
17:47:47 1565686067131 confution matrix[[0 0 4 0 0]
 [0 0 4 0 0]
 [0 0 4 0 0]
 [0 0 8 0 0]
 [0 0 5 0 0]]
17:47:47 1565686067851 training Start
17:47:47 1565686067914 step 0, accuracy nan
17:47:48 1565686068375 step 100, accuracy nan
17:47:48 1565686068607 training Finish
17:47:48 1565686068613 test Start
17:47:48 1565686068662 test finish
17:47:48 1565686068664 2-fold 2th
17:47:48 1565686068664 accuracy : 0.2
17:47:48 1565686068664 precision : 0.04
17:47:48 1565686068664 recall : 0.2
17:47:48 1565686068664 f1 Score : 0.06666666666666668
17:47:48 1565686068664 confution matrix[[0 0 0 0 6]
 [0 0 0 0 6]
 [0 0 0 0 6]
 [0 0 0 0 2]
 [0 0 0 0 5]]
17:47:48 1565686068665 total Accuracy : 0.18
17:47:48 1565686068665 total Precision : 0.036000000000000004
17:47:48 1565686068665 total Recall : 0.2
17:47:48 1565686068665 total f1 score : 0.06091954022988507
17:50:30 1565686230126 training Start
17:50:31 1565686231197 step 0, accuracy 0.1
17:50:31 1565686231327 step 10, accuracy 0.5
17:50:31 1565686231453 step 20, accuracy 0.5
17:50:31 1565686231572 step 30, accuracy 0.5
17:50:31 1565686231696 step 40, accuracy 0
17:50:31 1565686231815 step 50, accuracy 0
17:50:31 1565686231946 step 60, accuracy 0.5
17:50:32 1565686232054 step 70, accuracy 0.5
17:50:32 1565686232185 step 80, accuracy 0.5
17:50:32 1565686232303 step 90, accuracy 0.5
17:50:32 1565686232435 step 100, accuracy 0.5
17:50:32 1565686232551 step 110, accuracy 0.5
17:50:32 1565686232682 step 120, accuracy 0.5
17:50:32 1565686232812 step 130, accuracy 0.5
17:50:32 1565686232935 step 140, accuracy 0.5
17:50:33 1565686233065 step 150, accuracy 0.5
17:50:33 1565686233065 training Finish
17:50:33 1565686233069 test Start
17:50:33 1565686233106 test finish
17:50:33 1565686233111 2-fold 1th
17:50:33 1565686233111 accuracy : 0.12
17:50:33 1565686233111 precision : 0.024
17:50:33 1565686233111 recall : 0.2
17:50:33 1565686233111 f1 Score : 0.04285714285714285
17:50:33 1565686233111 confution matrix[[3 0 0 0 0]
 [5 0 0 0 0]
 [6 0 0 0 0]
 [5 0 0 0 0]
 [6 0 0 0 0]]
17:50:33 1565686233801 training Start
17:50:33 1565686233871 step 0, accuracy 0.3
17:50:34 1565686234007 step 10, accuracy 0.3
17:50:34 1565686234138 step 20, accuracy 0.3
17:50:34 1565686234283 step 30, accuracy 0.1
17:50:34 1565686234406 step 40, accuracy 0.3
17:50:34 1565686234520 step 50, accuracy 0.1
17:50:34 1565686234663 step 60, accuracy 0.1
17:50:34 1565686234788 step 70, accuracy 0.3
17:50:34 1565686234914 step 80, accuracy 0.3
17:50:35 1565686235052 step 90, accuracy 0.3
17:50:35 1565686235175 step 100, accuracy 0.3
17:50:35 1565686235308 step 110, accuracy 0.1
17:50:35 1565686235431 step 120, accuracy 0.3
17:50:35 1565686235557 step 130, accuracy 0.3
17:50:35 1565686235678 step 140, accuracy 0.3
17:50:35 1565686235817 step 150, accuracy 0.3
17:50:35 1565686235818 training Finish
17:50:35 1565686235821 test Start
17:50:35 1565686235867 test finish
17:50:35 1565686235869 2-fold 2th
17:50:35 1565686235869 accuracy : 0.16
17:50:35 1565686235869 precision : 0.032
17:50:35 1565686235870 recall : 0.2
17:50:35 1565686235870 f1 Score : 0.05517241379310346
17:50:35 1565686235870 confution matrix[[0 0 7 0 0]
 [0 0 5 0 0]
 [0 0 4 0 0]
 [0 0 5 0 0]
 [0 0 4 0 0]]
17:50:35 1565686235871 total Accuracy : 0.14
17:50:35 1565686235871 total Precision : 0.028
17:50:35 1565686235871 total Recall : 0.2
17:50:35 1565686235871 total f1 score : 0.04901477832512316
17:51:40 1565686300183 training Start
17:51:41 1565686301249 step 0, accuracy 0.4
17:51:41 1565686301388 step 10, accuracy 0.2
17:51:41 1565686301512 step 20, accuracy 0.1
17:51:41 1565686301639 step 30, accuracy 0.1
17:51:41 1565686301764 step 40, accuracy 0.1
17:51:41 1565686301896 step 50, accuracy 0.1
17:51:42 1565686302015 step 60, accuracy 0.1
17:51:42 1565686302148 step 70, accuracy 0.1
17:51:42 1565686302263 step 80, accuracy 0.1
17:51:42 1565686302394 step 90, accuracy 0.1
17:51:42 1565686302511 step 100, accuracy 0.1
17:51:42 1565686302639 step 110, accuracy 0.1
17:51:42 1565686302750 step 120, accuracy 0.1
17:51:42 1565686302883 step 130, accuracy 0.1
17:51:43 1565686303013 step 140, accuracy 0.1
17:51:43 1565686303138 step 150, accuracy 0.1
17:51:43 1565686303273 step 160, accuracy 0.1
17:51:43 1565686303407 step 170, accuracy 0.1
17:51:43 1565686303537 step 180, accuracy 0.1
17:51:43 1565686303664 step 190, accuracy 0.1
17:51:43 1565686303800 step 200, accuracy 0.1
17:51:43 1565686303930 step 210, accuracy 0.1
17:51:44 1565686304056 step 220, accuracy 0.1
17:51:44 1565686304183 step 230, accuracy 0.1
17:51:44 1565686304314 step 240, accuracy 0.1
17:51:44 1565686304443 step 250, accuracy 0.1
17:51:44 1565686304561 step 260, accuracy 0.2
17:51:44 1565686304693 step 270, accuracy 0.2
17:51:44 1565686304815 step 280, accuracy 0.2
17:51:44 1565686304946 step 290, accuracy 0.1
17:51:45 1565686305066 step 300, accuracy 0.1
17:51:45 1565686305185 step 310, accuracy 0.1
17:51:45 1565686305319 step 320, accuracy 0.2
17:51:45 1565686305448 step 330, accuracy 0.1
17:51:45 1565686305580 step 340, accuracy 0.1
17:51:45 1565686305699 step 350, accuracy 0.1
17:51:45 1565686305824 step 360, accuracy 0.1
17:51:45 1565686305950 step 370, accuracy 0.2
17:51:46 1565686306081 step 380, accuracy 0.3
17:51:46 1565686306194 step 390, accuracy 0.1
17:51:46 1565686306302 step 400, accuracy 0.2
17:51:46 1565686306433 step 410, accuracy 0.2
17:51:46 1565686306555 step 420, accuracy 0.2
17:51:46 1565686306691 step 430, accuracy 0.2
17:51:46 1565686306818 step 440, accuracy 0.2
17:51:46 1565686306936 step 450, accuracy 0.2
17:51:47 1565686307063 step 460, accuracy 0.2
17:51:47 1565686307179 step 470, accuracy 0.2
17:51:47 1565686307307 step 480, accuracy 0.2
17:51:47 1565686307451 step 490, accuracy 0.2
17:51:47 1565686307561 step 500, accuracy 0.3
17:51:47 1565686307683 step 510, accuracy 0.1
17:51:47 1565686307820 step 520, accuracy 0.1
17:51:47 1565686307945 step 530, accuracy 0.1
17:51:48 1565686308070 step 540, accuracy 0.1
17:51:48 1565686308196 step 550, accuracy 0.1
17:51:48 1565686308305 step 560, accuracy 0.1
17:51:48 1565686308418 step 570, accuracy 0.1
17:51:48 1565686308535 step 580, accuracy 0.1
17:51:48 1565686308649 step 590, accuracy 0.1
17:51:48 1565686308772 step 600, accuracy 0.1
17:51:48 1565686308880 step 610, accuracy 0.1
17:51:49 1565686309004 step 620, accuracy 0.1
17:51:49 1565686309102 step 630, accuracy 0.1
17:51:49 1565686309242 step 640, accuracy 0.1
17:51:49 1565686309364 step 650, accuracy 0.1
17:51:49 1565686309489 step 660, accuracy 0.1
17:51:49 1565686309616 step 670, accuracy 0.1
17:51:49 1565686309747 step 680, accuracy 0.2
17:51:49 1565686309871 step 690, accuracy 0.2
17:51:49 1565686309998 step 700, accuracy 0.2
17:51:50 1565686310122 step 710, accuracy 0.3
17:51:50 1565686310244 step 720, accuracy 0.1
17:51:50 1565686310372 step 730, accuracy 0.1
17:51:50 1565686310500 step 740, accuracy 0.1
17:51:50 1565686310623 step 750, accuracy 0.1
17:51:50 1565686310747 step 760, accuracy 0.1
17:51:50 1565686310873 step 770, accuracy 0.3
17:51:51 1565686311005 step 780, accuracy 0.1
17:51:51 1565686311137 step 790, accuracy 0.1
17:51:51 1565686311257 step 800, accuracy 0.1
17:51:51 1565686311384 step 810, accuracy 0.1
17:51:51 1565686311500 step 820, accuracy 0.1
17:51:51 1565686311621 step 830, accuracy 0.3
17:51:51 1565686311751 step 840, accuracy 0.3
17:51:51 1565686311890 step 850, accuracy 0.3
17:51:52 1565686312014 step 860, accuracy 0.1
17:51:52 1565686312133 step 870, accuracy 0.1
17:51:52 1565686312264 step 880, accuracy 0.1
17:51:52 1565686312397 step 890, accuracy 0.1
17:51:52 1565686312526 step 900, accuracy 0.1
17:51:52 1565686312667 step 910, accuracy 0.1
17:51:52 1565686312809 step 920, accuracy 0.3
17:51:52 1565686312929 step 930, accuracy 0.3
17:51:53 1565686313056 step 940, accuracy 0.1
17:51:53 1565686313182 step 950, accuracy 0.1
17:51:53 1565686313299 step 960, accuracy 0.1
17:51:53 1565686313433 step 970, accuracy 0.1
17:51:53 1565686313543 step 980, accuracy 0.1
17:51:53 1565686313673 step 990, accuracy 0.3
17:51:53 1565686313800 step 1000, accuracy 0.3
17:51:53 1565686313924 step 1010, accuracy 0.3
17:51:54 1565686314064 step 1020, accuracy 0.3
17:51:54 1565686314194 step 1030, accuracy 0.3
17:51:54 1565686314302 step 1040, accuracy 0.3
17:51:54 1565686314426 step 1050, accuracy 0.3
17:51:54 1565686314550 step 1060, accuracy 0.3
17:51:54 1565686314670 step 1070, accuracy 0.3
17:51:54 1565686314799 step 1080, accuracy 0.2
17:51:54 1565686314930 step 1090, accuracy 0.3
17:51:55 1565686315037 step 1100, accuracy 0.3
17:51:55 1565686315166 step 1110, accuracy 0.3
17:51:55 1565686315288 step 1120, accuracy 0.3
17:51:55 1565686315420 step 1130, accuracy 0.3
17:51:55 1565686315548 step 1140, accuracy 0.3
17:51:55 1565686315666 step 1150, accuracy 0.3
17:51:55 1565686315799 step 1160, accuracy 0.3
17:51:55 1565686315934 step 1170, accuracy 0.3
17:51:56 1565686316068 step 1180, accuracy 0.3
17:51:56 1565686316190 step 1190, accuracy 0.3
17:51:56 1565686316302 step 1200, accuracy 0.3
17:51:56 1565686316431 step 1210, accuracy 0.3
17:51:56 1565686316560 step 1220, accuracy 0.5
17:51:56 1565686316696 step 1230, accuracy 0.5
17:51:56 1565686316823 step 1240, accuracy 0.5
17:51:56 1565686316952 step 1250, accuracy 0.5
17:51:57 1565686317072 step 1260, accuracy 0.3
17:51:57 1565686317196 step 1270, accuracy 0.5
17:51:57 1565686317323 step 1280, accuracy 0.5
17:51:57 1565686317431 step 1290, accuracy 0.5
17:51:57 1565686317546 step 1300, accuracy 0.5
17:51:57 1565686317659 step 1310, accuracy 0.5
17:51:57 1565686317777 step 1320, accuracy 0.5
17:51:57 1565686317906 step 1330, accuracy 0.5
17:51:58 1565686318026 step 1340, accuracy 0.5
17:51:58 1565686318147 step 1350, accuracy 0.5
17:51:58 1565686318265 step 1360, accuracy 0.5
17:51:58 1565686318373 step 1370, accuracy 0.5
17:51:58 1565686318490 step 1380, accuracy 0.5
17:51:58 1565686318612 step 1390, accuracy 0.5
17:51:58 1565686318734 step 1400, accuracy 0.5
17:51:58 1565686318851 step 1410, accuracy 0.5
17:51:58 1565686318976 step 1420, accuracy 0.5
17:51:59 1565686319108 step 1430, accuracy 0.5
17:51:59 1565686319257 step 1440, accuracy 0.5
17:51:59 1565686319396 step 1450, accuracy 0.5
17:51:59 1565686319530 step 1460, accuracy 0.6
17:51:59 1565686319672 step 1470, accuracy 0.5
17:51:59 1565686319815 step 1480, accuracy 0.5
17:51:59 1565686319957 step 1490, accuracy 0.5
17:52:00 1565686320102 step 1500, accuracy 0.6
17:52:00 1565686320247 step 1510, accuracy 0.5
17:52:00 1565686320377 step 1520, accuracy 0.5
17:52:00 1565686320509 step 1530, accuracy 0.5
17:52:00 1565686320642 step 1540, accuracy 0.6
17:52:00 1565686320782 step 1550, accuracy 0.6
17:52:00 1565686320921 step 1560, accuracy 0.9
17:52:01 1565686321056 step 1570, accuracy 0.6
17:52:01 1565686321182 step 1580, accuracy 0.5
17:52:01 1565686321312 step 1590, accuracy 0.5
17:52:01 1565686321454 step 1600, accuracy 0.5
17:52:01 1565686321593 step 1610, accuracy 0.6
17:52:01 1565686321725 step 1620, accuracy 0.5
17:52:01 1565686321856 step 1630, accuracy 0.5
17:52:01 1565686321984 step 1640, accuracy 0.6
17:52:02 1565686322117 step 1650, accuracy 0.5
17:52:02 1565686322250 step 1660, accuracy 0.6
17:52:02 1565686322391 step 1670, accuracy 0.5
17:52:02 1565686322523 step 1680, accuracy 0.6
17:52:02 1565686322652 step 1690, accuracy 0.6
17:52:02 1565686322783 step 1700, accuracy 0.6
17:52:02 1565686322900 step 1710, accuracy 0.6
17:52:03 1565686323041 step 1720, accuracy 0.6
17:52:03 1565686323173 step 1730, accuracy 1
17:52:03 1565686323302 step 1740, accuracy 0.8
17:52:03 1565686323435 step 1750, accuracy 1
17:52:03 1565686323547 step 1760, accuracy 1
17:52:03 1565686323676 step 1770, accuracy 0.6
17:52:03 1565686323807 step 1780, accuracy 0.6
17:52:03 1565686323938 step 1790, accuracy 0.6
17:52:04 1565686324068 step 1800, accuracy 0.6
17:52:04 1565686324202 step 1810, accuracy 0.6
17:52:04 1565686324333 step 1820, accuracy 0.8
17:52:04 1565686324459 step 1830, accuracy 0.6
17:52:04 1565686324591 step 1840, accuracy 0.6
17:52:04 1565686324724 step 1850, accuracy 0.8
17:52:04 1565686324862 step 1860, accuracy 0.9
17:52:05 1565686325012 step 1870, accuracy 0.6
17:52:05 1565686325144 step 1880, accuracy 0.9
17:52:05 1565686325278 step 1890, accuracy 0.6
17:52:05 1565686325409 step 1900, accuracy 0.6
17:52:05 1565686325547 step 1910, accuracy 0.9
17:52:05 1565686325684 step 1920, accuracy 0.6
17:52:05 1565686325803 step 1930, accuracy 0.6
17:52:05 1565686325917 step 1940, accuracy 1
17:52:06 1565686326051 step 1950, accuracy 1
17:52:06 1565686326183 step 1960, accuracy 0.6
17:52:06 1565686326324 step 1970, accuracy 0.6
17:52:06 1565686326455 step 1980, accuracy 0.9
17:52:06 1565686326594 step 1990, accuracy 0.6
17:52:06 1565686326726 step 2000, accuracy 1
17:52:06 1565686326856 step 2010, accuracy 1
17:52:06 1565686326988 step 2020, accuracy 0.9
17:52:07 1565686327119 step 2030, accuracy 0.6
17:52:07 1565686327250 step 2040, accuracy 0.9
17:52:07 1565686327373 step 2050, accuracy 1
17:52:07 1565686327499 step 2060, accuracy 1
17:52:07 1565686327632 step 2070, accuracy 1
17:52:07 1565686327761 step 2080, accuracy 1
17:52:07 1565686327891 step 2090, accuracy 0.6
17:52:08 1565686328031 step 2100, accuracy 0.7
17:52:08 1565686328176 step 2110, accuracy 0.9
17:52:08 1565686328303 step 2120, accuracy 0.6
17:52:08 1565686328422 step 2130, accuracy 0.6
17:52:08 1565686328560 step 2140, accuracy 0.6
17:52:08 1565686328698 step 2150, accuracy 0.9
17:52:08 1565686328834 step 2160, accuracy 0.6
17:52:08 1565686328968 step 2170, accuracy 0.9
17:52:09 1565686329094 step 2180, accuracy 1
17:52:09 1565686329231 step 2190, accuracy 0.8
17:52:09 1565686329370 step 2200, accuracy 1
17:52:09 1565686329501 step 2210, accuracy 1
17:52:09 1565686329628 step 2220, accuracy 0.9
17:52:09 1565686329751 step 2230, accuracy 0.9
17:52:09 1565686329887 step 2240, accuracy 0.9
